[strings]
# site
site = meta-rl

# Mode: train,test,infer,analysis,serve
mode = train

# Dataset: mnist,fashion_mst,cifar10,cifar100,tiny_imagenet
dataset = cifar10

# directories
data_dir = dataset
features_dir = features
infer_dir = infer
model_dir = model
output_dir = output
log_dir = log
resources = resources
certificate = None

# set the optimizer to use gd, adadelta, adagrad, adam, rmsprop - flower = rmsprop, cifar10 = rmsprop, dog_cat = rmsprop, caltech = adadelta
optimizer = adam

# gpus to use
gpu_to_use = 0

# input dimensions: mnist-28x28x1, cifar-32x32x3
#input_dimensions = 28x28x1

[ints]
# number of layers
num_layers = 2

# set the hidden size
num_hidden = 35

# set the number of epochs - 150
train_num_epochs = 25

# number of steps in one cycle
num_child_steps_per_cycle = 50

# learning rate decay
num_steps_per_decay = 50

# number of Episodes of RL
num_episodes = 15000

# set the batch size
train_batch_size = 32
#test_batch_size = 10000

# maximum depth of the network - 9, 18, 34, 50, 101, 152
#max_depth = 9

# minimum number of channels
initial_filters = 64

# set the number of training steps
num_train_steps = -1

# set testing percentage
testset_proportion = 25

# serving port
port = 8500

[floats]
# exploration
exploration = 0.8
discount_factor = 0.99

# set the learning rate
learning_rate = 0.0006
learning_rate_decay_factor = 0.90


